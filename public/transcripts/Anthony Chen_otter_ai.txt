Speaker 1  0:37  
Hello hello. How are you? Hi, Gary. Yes. How you doing? Good. How are you? Yeah. Nice to meet you on Zoom.

Unknown Speaker  0:52  
Nice to meet you too, or thanks.

Speaker 1  0:55  
So, just to introduce myself I joined UCLA about five years ago in the electrical and computer engineering department. My research has been on human computer interaction Yeah, especially on building AI tools to support different domain users. For example, doctors trying to diagnose patients with tumors. So that was one of the focus area and so recently, I've been thinking about how AI can assist college admission review process. And I've been reading some literature's and I have reached out to people like you, who are the experts just to see what do you think of this idea? What general advice you have, and I can also show you a tentative research pan I'm thinking about,

Speaker 2  1:59  
okay, great, great. No, yeah, I'm happy to have it out where I can answer answer any questions. I'm, I'm curious if you don't mind and you're able to share like, what what are some things you're hearing so far from some of the admission folks that you've spoken with?

Speaker 1  2:15  
Actually, you're the first one. Okay, all right. Yeah. Okay to reach out to more people by you because I think multiple of the people I talked to in my school and incresed they all mentioned you as the person that you'd talk to as though you probably at the nexus of

Speaker 2  2:38  
this research. All right. No, I'm happy to happen to kind of kind of get you started as best I can. So So yeah, I mean, what what are some questions you have, I mean, what can we how I can help?

Unknown Speaker  2:49  
Okay, I mean, let me share my screen

Speaker 1  2:57  
okay, you can see it. Yes, thanks. Great. So, the overall goal is to provide to support for admission officers to review college application materials. So for my literature reading, I found there has been some work on using machine learning models to just predict or just to divide applications into ports based on some quantitative values, like standardized test scores or some of demographic information. So this property has been explored already. So I am thinking about focusing on this texture information part like essays, writing supplements, letters, how AI can help reviewing this textual material.

Speaker 2  3:55  
Okay, let me let me start with a couple things, just ways in which I think UCLA and kind of as a result, you see are a little different than lots of other colleges and universities approach admission. So we do not collect letters of recommendation, okay, at all. So none of UCS consider really letters of recommendation in their review process. Now, there may be some outlier programs, you know, like theater, film and television might ask for a letter as a part of their supplemental application to talk about a student's talent in particular, or theater or something along those lines. So they're very small exceptions, but generally speaking, we don't look at or consider letters of recommendation. In our process. We don't consider standardized testing. At UC at all. None of that you see is what we call test free we don't consider a CT or a CT for any for admission or scholarship purposes full stop. So no no SATs or AC T consideration for our freshmen and for our freshmen applications. Every freshman application has read at least twice before by a person to independent reviews of the application. So if you read it, read the app first and you come score the application and I read the application after you don't get to see how you reviewed the application or any note you left. So it's intended to be that way to make sure we're similar in our rating. You know, but that if we are disparate meaning where we're far apart and the way that we reviewed the application, then a third review of the application happens, but a senior staff person, seasoned reviewer in mission office you know, I, I want to talk through this and think and see if their ideas, but I will tell you I'm very hesitant to engage with AI as it relates to application review. I think that would be challenging to defend publicly. I think people expect that human beings are reading their applications when they submit them. We don't realize we don't you know, organize apps based on academic performance. And we entered in 46,000 Freshmen applications this past year. Every single one of them was read at least twice. before a decision is made. So I mean, I as it relates to you know, the quality control or something like I don't, perhaps there's some possibility there. I don't I don't have my head around what that would look like quite yet. But when it comes to actually turning over a review of the application or a review of some piece of the application of AI, I would be pretty hesitant on that front and we would probably have to engage with our faculty to for them for it to even be considered much, much less implemented. So I don't want to start off negative I just want to kind of set that playing field so that you kind of understand a little bit about kind of our review process.

Speaker 1  6:54  
Yeah, sure. So the reason I mentioned earlier about doctors working with AI, I think it's a little bit analogous. You probably will be hesitant if your doctor is totally rely on AI to diagnose your health issues. I think the the analogy is we don't want AI to replace doctors or application reviewers. We want to find kind of a sweet spot for humans to use AI as a tool to improve the process without jeopardizing the reviewing quality or incurring any safety or biases or any other issue. So that was kind of the research part.

Unknown Speaker  7:42  
Okay, that's helpful.

Speaker 1  7:46  
Yep. So I understand that if the ideal outcome will be, maybe we can develop an internal tool for the admission office service to use or even a publicly available tool for our college admission offices. That's the best outcome. Of course, the worst outcome will be we didn't find a feasible solution to use AI, then there will be also an expected result of this research. So here's my kind of a tentative research plan there will be three different phases. This is a very typical human centered research process in my own area. We would usually start off with a formative study in which we want to recruit people who reveal college applications to ask three sets of questions. The status quo, basically what is the current process? Describe to me what holistic review means to you. Describe a typical procedure of reviewing an applicant's material and what are the pain points? Currently, what what do you think are the programmatics steps or something you struggle with or something that needs to be addressed? In the reviewing process? And then expectations let's say there's a tool involving AI or some other computational means to help with this process? What kinds of support be useful, what other requirements and what kind of metrics would define the success of this tool? So in this first phase, we are trying to establish the basic understanding of the current status as well as issues to that can be addressed and expectations of the to support. And then after the first phase, we'll work on some initial design of the tool and then invite more reviewers. To let them go through the design. It could be like a sketch or a simple digital prototype of the software tool. And they would critique, offer some comments or concrete suggestions to help us improve the next iteration. And then finally, the last phase will involve very close to to ready version of the tool. It will be something we can access on the web. Could be a website, a web app that runs internally and with the VI, a yet another set of reviewing officers to try our prototype. Maybe they'll even try to review a few past applications. And then we'll measure the success based on the metrics we discussed earlier. So that's kind of the general research plan. I'm thinking about

Speaker 2  11:00  
okay, okay. Good. Well, a couple of just kind of somewhat random thoughts. One is related, but an area where we've we've even briefly talked about and discussed how AI might be useful and that is, kind of post admission but pre enrollment. One of the features of kind of the UC admission process, and this is somewhat distinctive to us, but other schools I think would find this useful too. We do not collect the high school transcript at the point of application. Okay, we ask students to self report all of their grades in the UC app. So they tell us all their classes and all their grades throughout high school and any college courses they've taken and that type of thing. So during the summer, we asked for any student who was committed to enroll to send us final high school transcripts and the validate what was reported in the application. We scan those transcripts to ensure that there aren't any problematic grades in the student's senior year because when they lie, they're in their senior year. So we haven't seen those grades. When we get those transcripts in the summer. That is a heavy lift and a very labor intensive process. I that is something where it's really just either verifying what's in the application or, you know, ensuring that there aren't problematic raids in the senior year. That's a really challenging and heavy lift each summer. So I I would love to think of some technology solutions potentially around that because that is a real heavy lift for our team.

Speaker 1  12:46  
So are those grades reported by the students? Are they just tabular data or what kind of formats?

Speaker 2  12:57  
Yeah, so it's when the students fill out the UC application. So they're, in most cases, they're selecting their courses from a drop down, they're selecting here and in the course from the drop down. And then ultimately, all of that is pushed to us in kind of an XML file that our campus receives and then pushes into we use a CRM or application review tool called slate that we use to kind of present all the application information to the student. And since everything comes from the UC app, we're not really we don't get any submissions from outside of what comes in the UC app, everything is coming through what the student reports and so when I think about you know, just some things that you know, when I when I think about like the what we call our personal insight questions. These are kind of our version of the college essay students. There are eight questions in the UC app students pick four of them to respond to. Perhaps there's something around analyzing those responses. You know, I want to I'm hesitant to do any kind of scoring around that. Because I, again, that's where I start to feel a little uncomfortable with we're turning over something that you know, the score or the application to something other than a person but maybe there's some role that AI can play in analyzing the personal insight questions, and I don't I don't know exactly what that what that might look like. But that's an area where I think there there might be some, some benefit. We often as it relates to assessing a student's academic performance. We often describe that assessment as being very contextual, and trying to understand a student's performance, excuse me in the context of the high school that they attend. And we mean that a couple different ways one, in terms of like a GPA, how does that constitute with other applicants over the past three years, and we keep subset of applicant data, you know, for the previous years, and then we can understand that students 3.8 might put them in the 95th percentile of applicants from that school to UCLA over the past three years. That gives us a way to understand the context of that GPA, and we have unweighted GPAs weighted GPAs. We have a number of honors AP IB courses that a student has taken. All these things we want to review contextually but the part around that that I think would be useful. That is it's kind of a you know, scanning a page for information and doing your own kind of mental triangulation is understanding the real depth of what's available, what courses are available to the student in that high school program. That's where I don't know how reliable the data is that we will have to compare that to in terms of the comprehensive nature of high school programs throughout the state and around the country and around the world. We don't have that. We do our best to understand based on that previous contextual information, but for example, if a student you know it isn't taking AP Calc as a senior, it's helpful for the reader to understand number one is AP Calc available to the student in their school. You know, and you know, if so, it may be one class that has 30 slots, and if you're not one of the 30 students that gets selected for AP count and your Outlook, you know, so those are things that help us deepen and better understand the context around academic performance. We also and then I'll stop talking for a minute because I don't want to ramble, but we use data from a tool called the College Board landscape. I don't know if you're familiar with college board landscape, but basically the College Board grater program that collects census data for the country, and gives us local information for the students the home address, and for their school address as it relates to different kinds of poverty. Statistics, crime rates, access to the internet, you know, things that help us to understand a little bit more about the environment in which a student is learning both both the school environment and the whole environment. Because again, that helps us to understand if the student is in a neighborhood where these statistics are very high as crime rates are, you know, percentage of high school graduates or you know, are those kinds of things that helps us to understand some of the challenges the student might face in both their home and environment. So we currently take that data and kind of processes and process it and present it to our readers in a way that's digestible. But is there a way to do that better? Is there a way that that AI might help us to analyze and understand that environment for for students, so I don't know if any of that is helpful, or if I'm not going in the right direction, but let me know if so or if not, pushed me with some questions that help me to get to what you need.

Speaker 1  18:26  
And from what I'm hearing so one way AI can be helpful is processing the reported great data that's usually in XML files, as you mentioned, right? So why what's the current approach? Why Why was it labor intensive to process those files?

Speaker 2  18:49  
Well, the processing and for the application review is not difficult. I mean, it's it's that comes through and is presented to the reader and, and something that kind of looks like a transcript. It's a grid and you can see through 12 and the list of classes and you know, are actually sorted by subject area so you can see the English classes nine through 12 all the math classes nine through 12. So that part I don't think is challenging. What I was referring to more as the summer matriculation process where we're actually having to take what was reported by the student in the application and kind of compare it to a transcript that we receive that it either comes as a paper document or sent electronically, but as a PDF, essentially, that that we then have to usually have either staff or students staff. Look at that document and see, are there any problematic grades? Is there anything that's different than what was reported in the app? And if so, then it's flagged for somebody you know, to review and determine whether we need to take any action based on that drop or based on that discrepancy with what was reported. So that that's where the labor intensive part I talked about was really more around that matriculation process. Not necessarily around like kind of evaluating the academic work in the application. The piece that I did mention is, you know, and this is where it's I don't know that AI can fix this because we just we just don't have the data to plug into it in terms of what does the high school curriculum look like? Individual high school that a student is attending throughout the country. And then, because if we knew that, then we could somehow understand the students the rigor of the student's high school program relative to what's actually available to the student in their school set. Right now, our best proxy for that is looking at how that students the rigor of the student's high school program compares to applicants from previous years from that school, which is a decent proxy, but it's not. It's not as comprehensive potentially as it as because you're only comparing it really what the subset that chose to apply, versus just generally what's available to the student in their school.

Speaker 1  21:05  
So this, this point you just mentioned, it might be suggesting that AI can help a reader gather some contextual information about an applicant.

Speaker 2  21:20  
Sure. Yeah. Now that that's a big part of what we like what we're trying to avoid as being formulaic in our approach to admission and kind of your question there. What does holistic review mean to you? It means we're not we're not doing things by formulas like We're hot. Back in the day when we consider test scores. It wasn't GPA plus LSAT equals urine or you're not like we want to be sure that we're reviewing academic performance and rigor and you know that in the context of the students school setting and kind of the opportunities available to them in that setting.

Speaker 1  21:56  
Yeah, so I'm guessing. Yeah, as I said, Maybe one way AI can help is not necessarily predicting or deciding on the admission result but trying to extract contextual information from either the application package or from other sources of data, which would otherwise be time consuming for the human to manually sift through.

Speaker 2  22:22  
Yeah, no, I think that I think you're I think you're right, like and that's what like the College Board landscape was really extremely helpful for us when that came around. Four years or four years ago or so is when that first kind of came on board because that really allowed us to understand, you know, we know a lot of neighborhoods here in California, but we don't know them all. And the ability for us to have something that's based on national census data. Better enables the reader to really understand home environment school environment for for the student and above and beyond just some of the academic measures that we have. So yeah, anything that can add additional contextual understanding for the reader is going to be useful.

Speaker 1  23:09  
Great. I think this kind of discussion is something I'm looking for. Find what what the AI be most useful appropriately. useful to the process, right? Good.

Unknown Speaker  23:36  
Any other thing that comes to mind?

Speaker 2  23:38  
Yeah, I'm trying to just kind of visually go through in my head, the application and kind of the different the different pieces you know, we will learn from an applicant if they're the first person in their family and earn a college degree we have an understanding of whether the student might be from a from a low income background. Based on how they report self portrait income in their family, we don't know race it and the city for the student that's that's kind of blocked because of prop 209. And now the Supreme Court case, we don't have any, any knowledge of the students racial or ethnic background. You know, the school we know and then something, as I said, is a real, real important piece for us. We asked the student to tell us about things are involved and engaged in outside of the classroom. And I think and I don't know if there's really a there, there, but I'll say this out loud. And you can tell me if this is useful in any way. So one of the things that I wish we could be better at is better understanding a student's level of engagement outside of class, kind of based on those personal circumstances. You know it there there are a number I mean, we're obviously a very competitive place. Our admit rate was 9% last year, so this is a very competitive, very competitive process. But we have plenty of students who are kind of filling all the boxes like they're they're doing lots of different activities. They're taking on lots of different leadership and all the things that they're engaged in things that you might consider kind of traditional high school kinds of activities, you know, clubs, organizations, athletics, newspapers, student government, all those kinds of things. But there are also a large number of students who are not as engaged in those things. Right, but they are engaged, you know, so So let's say you're a student who, you know, works a significant number of hours or you're a student who shares in the application that you have to take care of a family member at home or you're responsible for helping your younger siblings at homework at the end of each school day because both your parents are working. Like I think we can be better at catching and valuing those things in our review process. And maybe that's an area where AI can be helpful because I think sometimes we fall into the trap as much as we train our readers to kind of look for those things in the way that I kind of just described them. Could we be better at really understand a student's kind of non academic performance for lack of a better term, deeper understanding of a broader appreciation for what those kind of quote activities might look like. Does that make sense is that?

Speaker 1  26:33  
Yes, I'm curious. Are those information available somewhere in the application materials?

Speaker 2  26:41  
Well, it's always on the student so that this is where like, we depend on the student to tell us about these things. And if they do, then we can kind of act upon them. But you know, student will list all their activities and we give them guidance to say, that doesn't just mean school related. Tell us if you're working, there's a space in the app to report that. Tell us how you're using those earnings because a lot of times, like if it's if you're making money to just say you have shopping money or whatever, then that's not a bad thing. But that's different than a student who's like I'm working 20 plus hours a week to help keep the lights on in my house like we want to. We want to understand that a little bit. But when I talk about those other things like taking care of a elderly grandparent at home or younger siblings or that kind of thing. If the student tells us either in that activities list or they share it somewhere in their personal insight question responses, then we can consider it but we have to rely on the student telling us about that for us to be able to take any kind of action on it.

Speaker 1  27:47  
Yeah, so maybe AI can can help the reader pay attention if they omit this kind of mentioning of these kinds of activities.

Speaker 2  27:59  
Yeah, I don't I don't, I don't know. I mean, you obviously to say you know AI better than I do is an understatement, but I think what I'm thinking about is is more of if it's mentioned in some way, kind of highlighting it for the reader in a way that they they kind of see its value sense, you know, so that if it's embedded in one of those P IQ responses that we can somehow maybe elevated for the reader in a way that they're picking out some of those important parts out of the personal insight questions. I we train them to and I sincerely hope that every reader reads every word of every personal insight question response but in the event that that doesn't happen if there's some way that AI can pick up on some of the highlights or themes or things like that, that's that that might be useful.

Speaker 1  28:59  
Yeah, that makes sense. Cool. So we only have two minutes left. So that's your ideas have been very helpful. I took a lot of notes. So for for the next step. I'm wondering, could you help me connect to other potential collaborators or even people who actually perform the reviewing process?

Speaker 2  29:29  
Well, as for the second part, I mean, you know, I on some of my senior staff, we all read apps, so it's there, okay. There's interest in engaging with some of us. Like I can certainly make some of your senior staff and readers available to kind of talk to you in a forum like this and give any feedback, or that type of thing.

Unknown Speaker  29:50  
That'd be great.

Speaker 2  29:52  
Yeah, I'd be happy to. You know, I want to make sure they're cool with it first, but I'm happy to reach out to some of my colleagues in the UC system at the campuses and see if there's any interest in in a conversation like this. I don't know if they have faculty on their campuses that might be engaging them in similar conversations, but I'm happy to kind of put a general ask out there. That would be great to see if there's if there's some interest there. As far as colleagues from non UCS, I might be I'd be willing to reach out to maybe a couple of folks privately and see if there's interest. And if there is then I'm happy to share their contact info with you. But I mean, look, most of their information is public. So if you wanted to reach out to the director at USC, and at the Claremont Colleges and Santa Clara and Chapman and Stanford, I mean, like, you could find that contact info pretty easily. So there's nothing stopping you from doing that. If you'd like. You know, but I'm happy to at least for a couple of folks that I know, just got some non UCC voices. I'm happy to reach out I can't guarantee they'll say yes or they want to, to engage, but I can I can certainly put the ask out there.

Transcribed by https://otter.ai
